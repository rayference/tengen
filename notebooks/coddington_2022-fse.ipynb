{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coddington, 2022 - Full Spectrum Extension (FSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import typing as t\n",
    "\n",
    "import requests\n",
    "import xarray as xr\n",
    "\n",
    "import tengen\n",
    "from tengen import unit_registry as ureg\n",
    "\n",
    "# Dataset attributes\n",
    "\n",
    "IDENTIFIER = \"coddington_2022-fse\"\n",
    "DATA_URL = \"https://lasp.colorado.edu/lisird/resources/lasp/hsrs/v2/\"\n",
    "TITLE = \"Total and Spectral Solar Irradiance Sensor-1 (TSIS-1) Hybrid Solar Reference Spectrum (HSRS), Version 2 - Full Spectrum Extension\"\n",
    "INSTITUTION = \"Laboratory for Atmospheric and Space Physics\"\n",
    "SOURCE = \"TSIS-1 Spectral Irradiance Monitor (SIM), CubeSat Compact SIM (CSIM), Air Force Geophysical Laboratory ultraviolet solar irradiance balloon observations, ground-based Quality Assurance of Spectral Ultraviolet Measurements In Europe Fourier transform spectrometer solar irradiance observations, Kitt Peak National Observatory solar transmittance atlas and the semi-empirical Solar Pseudo-Transmittance Spectrum atlas with independent observations and theoretical knowledge where no observations exist\"\n",
    "REFERENCES = \"Coddington, O., Richard, E., Harber, D., Pilewskie, P., Woods, T. N., Snow, M., Chance, K., Liu, X., and Sun, K. (2022, accepted) Version 2 of the TSIS-1 Hybrid Solar Reference Spectrum and Extension to the Full Spectrum, Earth and Space Science Journal.\"\n",
    "\n",
    "# Notebook configuration\n",
    "\n",
    "UPDATE_CACHE = False  # change to True to update the cache when running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAMES = [\n",
    "    \"binned_fs_\",\n",
    "    \"fs_\",\n",
    "]\n",
    "FILENAME_SUFFIX = \"hybrid_reference_spectrum_c2022-11-30_with_unc.nc\"\n",
    "\n",
    "\n",
    "def download(\n",
    "    url: str,\n",
    "    path: t.Optional[os.PathLike] = None,\n",
    ") -> None:\n",
    "    \"\"\"Download original data from url.\n",
    "\n",
    "    Args:\n",
    "        url: URL to download data from.\n",
    "        path: Path to save data to (must be a directory). If None, a temporary\n",
    "            directory is created and the raw data is saved there.\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        tmpdir = tempfile.TemporaryDirectory()\n",
    "        path = tmpdir.name\n",
    "\n",
    "    # path must be a directory\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"Path {path} must be a directory.\")\n",
    "\n",
    "    for filename in FILENAMES:\n",
    "        file = f\"{filename}{FILENAME_SUFFIX}\"\n",
    "        response = requests.get(url + file)\n",
    "        with open(os.path.join(path, file), \"wb\") as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_missing_carats_units(s: str) -> str:\n",
    "    \"\"\"Add missing carats to a malformed unit string.\n",
    "\n",
    "    Will format a string 'm-1' to 'm^-1'.\n",
    "\n",
    "    Args:\n",
    "        s: Unit string.\n",
    "\n",
    "    Returns:\n",
    "        Formatted unit string.\n",
    "    \"\"\"\n",
    "    where = [m.start() for m in re.finditer(\"[-+][0-9]\", s)]\n",
    "\n",
    "    for count, i in enumerate(where):\n",
    "        s = s[: i + count] + \"^\" + s[i + count :]\n",
    "\n",
    "    where2 = [m.start() for m in re.finditer(\"[a-z ][0-9]\", s)]\n",
    "\n",
    "    for count, i in enumerate(where2):\n",
    "        s = s[: i + count + 1] + \"^\" + s[i + count + 1 :]\n",
    "    return s\n",
    "\n",
    "\n",
    "def format(\n",
    "    data: os.PathLike,\n",
    "    path: t.Optional[os.PathLike] = None,\n",
    ") -> t.Optional[t.List[xr.Dataset]]:\n",
    "    \"\"\"Format original data.\n",
    "\n",
    "    Args:\n",
    "        data: Path to original data directory.\n",
    "        path: Path to save formatted data to. If None, formatted datasets are\n",
    "            returned.\n",
    "\n",
    "    Returns:\n",
    "        None or formatted datasets.\n",
    "    \"\"\"\n",
    "    # check that path is a directory\n",
    "    if path is not None and not os.path.isdir(path):\n",
    "        raise ValueError(f\"Path {path} must be a directory.\")\n",
    "\n",
    "    if path is None:\n",
    "        datasets = []\n",
    "\n",
    "    for filename in FILENAMES:\n",
    "        file = f\"{data}/{filename}{FILENAME_SUFFIX}\"\n",
    "\n",
    "        with xr.open_dataset(file, engine=\"netcdf4\") as ds:\n",
    "            # parse wavelength data\n",
    "            w_units = ds[\"Vacuum Wavelength\"].attrs[\"units\"]\n",
    "            w_magnitude = ds[\"Vacuum Wavelength\"].values\n",
    "            w = ureg.Quantity(w_magnitude, w_units)\n",
    "\n",
    "            # parse solar spectral irradiance data\n",
    "            ssi_units = format_missing_carats_units(ds[\"SSI\"].attrs[\"units\"])\n",
    "            ssi_magnitude = ds[\"SSI\"].values\n",
    "            ssi = ureg.Quantity(ssi_magnitude, ssi_units)\n",
    "\n",
    "        _attrs = {\n",
    "            \"title\": f\"{TITLE} (binned)\" if \"binned\" in filename else TITLE,\n",
    "            \"institution\": INSTITUTION,\n",
    "            \"source\": SOURCE,\n",
    "            \"references\": REFERENCES,\n",
    "        }\n",
    "        ds = tengen.to_dataset(ssi=ssi, w=w, data_url=DATA_URL, attrs=_attrs)\n",
    "\n",
    "        if path is not None:\n",
    "            filename = (\n",
    "                f\"{IDENTIFIER}_binned.nc\"\n",
    "                if \"binned\" in filename\n",
    "                else f\"{IDENTIFIER}.nc\"\n",
    "            )\n",
    "            filename = os.path.join(path, filename)\n",
    "            ds.to_netcdf(filename)\n",
    "        else:\n",
    "            datasets.append(ds)\n",
    "\n",
    "    if path is None:\n",
    "        return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (leave this cell as is)\n",
    "\n",
    "if UPDATE_CACHE:\n",
    "    original_data_dir = tengen.RAW_DATA_DIR / IDENTIFIER\n",
    "    original_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    download(url=DATA_URL, path=original_data_dir)\n",
    "\n",
    "    formatted_data_dir = tengen.FORMATTED_DATA_DIR / IDENTIFIER\n",
    "    formatted_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    format(data=original_data_dir, path=formatted_data_dir)\n",
    "\n",
    "else:\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        download(url=DATA_URL, path=tmpdir)\n",
    "        dataset = format(data=tmpdir, path=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tengen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d2d83a8f2df0639f36d4cb071992b55f90f953abd83315b346d889f6b3fbf4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
